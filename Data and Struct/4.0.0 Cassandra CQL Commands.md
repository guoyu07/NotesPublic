http://docs.datastax.com/en/cql/3.3/cql/cql_reference/cqlCommandsTOC.html
# Types
http://docs.datastax.com/en/cql/3.3/cql/cql_reference/cql_data_types_c.html

* uuid						A UUID in standard UUID format

* ascii		strings
* varchar					UTF-8 encoded string
* text						UTF-8 encoded string

* tinyint					1-byte
* smallint					2-bytes
* int						32-bit signed integer
* bigint	
* counter	int				Distributed counter value (64-bit long)
* decimal	int, float
* double
* float

* blob
* boolean					true or false

* date						Date string, such as 2015-05-0
* time						Time string, such as 13:30:54.234
* timestamp					Date plus time, encoded as 8 bytes since epoch. You can change the format by setting the time_format property in the [ui] section of the cqlshrc file.
* timeuuid					Type 1 UUID only

* inet		strings			IP address string in IPv4 or IPv6 format

* list 		n/a				ordered elements [ literal, literal, literal ]
* map						A JSON-style array { literal : literal, literal : literal ... }
* set					    non-ordered elements: { literal, literal, literal }
* tuple						tuple<int, text, float>  ==> (3, 'Aario', 2.0)
* frozen

* varint						var int   Arbitrary-precision integer

## Counter Type
A counter is a special column for storing a number that is changed in increments.

A counter column must have the datatype counter data type. This data type cannot be assigned to a column that serves as the primary key or partition key. To implement a counter column, create a table that only includes:
* The primary key (can be one or more columns)
* The counter column
Many counter-related settings can be set in the cassandra.yaml file. A counter column cannot be indexed or deleted.. Cassandra rejects USING TIMESTAMP or USING TTL when updating a counter column.

```
cqlsh> CREATE TABLE views (
		name varchar,
		counts counter,
		PRIMARY KEY (name)
	 );
	 
cqlsh> UPDATE views SET counts = counts + 2 WHERE name = 'Aario';
```

## Blob Type
* ${type}AsBlob($value)			e.g. intAsBlob(5)
* blobAs${Type}($value)			e.g. blobAsBigInt(4)
```
cqlsh> CREATE TABLE biography ( 
		username varchar PRIMARY KEY,
		bio blob
	 );
	 
cqlsh> INSERT INTO biography (username, bio) VALUES ('Aario', bigintAsBlob(3));

cqlsh> SELECT * FROM biography;
|[
	 username | bio
	----------+--------------------
		Aario | 0x0000000000000003
]|

cqlsh> ALTER TABLE biography ADD id bigint;
cqlsh> INSERT INTO biography (username, id) VALUES ('Aario', blobAsBigint(0x0000000000000003));
cqlsh> SELECT * FROM biography;
|[
	 username | bio                | id
	----------+--------------------+----
		Aario | 0x0000000000000003 |  3
]|
```

## Using frozen in a Collection
frozen<> is only allowed on collections, tuples, and user-defined types (got text)

Collection types cannot be nested, but frozen collection types can be nested inside frozen or non-frozen collections. For example, you may define a list within a list, provided the inner list is frozen:

```
Error:    list<list<int>>			// error!!!
list<frozen <list<int>>>			// ok!
frozen<list<int>>  is same as list<int>
```


Cassandra treats the value of a frozen type as a blob. The entire value must be overwritten.

You cannot use non-frozen collections for primary key columns. However, you can use frozen collections for primary key columns.
```
cqlsh> CREATE TABLE test.users (
		  emails set<text>				// {'AarioAi@gmail', 'AarioAi@luexu.com'}
	 );

cqlsh> CREATE TABLE test.set_frozen_list (
		id uuid PRIMARY KEY,
		tegument set<frozen<list<int>>>
	 );	 
cqlsh> INSERT INTO test.set_frozen_list (id, tegument) VALUES (
		79998560-c144-11e6-9ffb-819d3fcf064a,
		{[100], [200]}
	 );
	
cqlsh> CREATE TABLE test.frozen_list (
		id uuid PRIMARY KEY,
		tegument frozen<list<int>>
	 );	 
cqlsh> INSERT INTO test.frozen_list (id, tegument) VALUES (
		79998560-c144-11e6-9ffb-819d3fcf064a,
		[200]
	 );



cqlsh> CREATE TYPE IF NOT EXISTS test.fullname (
		first_name text,
		last_name text
	 );
cqlsh> CREATE TABLE test.users (
	  id uuid PRIMARY KEY,
	  name frozen <fullname>,
	  direct_reports set<frozen <fullname>>,     // a collection set
	  score set<frozen<set<int>>>              // a set with a nested frozen set
	);
```

## UUID and Timeuuid Functions
* uuid()  generates a random Type 4 UUID suitable for use in INSERT or SET statements.
* timeuuid()
	- dateOf()
	- now()					a unique timeuuid in milliseconds, e.g. 79998560-c144-11e6-9ffb-819d3fcf064a
	- minTimeuuid(string $datetime)
	- maxTimeuuid(string $datetime)
	- unixTimestampOf()
	- toDate($timeuuid | $timestamp)			 YYYY-MM-DD
	- toTimestamp($timeuuid | $date)
	- toUnixTimestamp($timeuuid | $timestamp | $date)

	
The values returned by minTimeuuid and maxTimeuuid functions are not true UUIDs in that the values do not conform to the Time-Based UUID generation process specified by the RFC 4122. The results of these functions are deterministic, unlike the now() function.

```
cqlsh> SELECT * FROM tb WHERE t > maxTimeuuid(2016-12-14 00:00+0800)
		AND t < minTimeuuid(2017-01-01 00:00+0800);
		
The min/maxTimeuuid example selects all rows where the timeuuid column, t, is strictly later than 2013-01-01 00:05+0000 but strictly earlier than 2013-02-02 10:00+0000. The t >= maxTimeuuid('2013-01-01 00:05+0000') does not select a timeuuid generated exactly at 2013-01-01 00:05+0000 and is essentially equivalent to t > maxTimeuuid('2013-01-01 00:05+0000').

cqlsh> CREATE TABLE sample_times (a int, b timestamp, c timeuuid, d bigint, PRIMARY KEY (a,b,c,d));

cqlsh> INSERT INTO sample_times (a,b,c,d) VALUES (1, toUnixTimestamp(now()), 50554d6e-29bb-11e5-b345-feff819cdc9f, toTimestamp(now()));

cqlsh> SELECT toDate(c) FROM sample_times;
```


# Tuple Type
```
cqlsh> CREATE TABLE collect_things (
	  k int PRIMARY KEY,
	  v tuple<int, text, float>,
	  z tuple<int, tuple<text, text>>)
	);
cqlsh> INSERT INTO collect_things (k, v, z) VALUES(0, (3, 'bar', 2.1), (1, ('Aario', 'Ai')));

cqlsh> SELECT * FROM collect_things;
|[
	 k | v               | z
	---+-----------------+----------------------
	 0 | (3, 'bar', 2.1) | (1, ('Aario', 'Ai'))
]

cqlsh> CREATE INDEX on collect_things (v);
cqlsh> SELECT * FROM collect_things WHERE v = (3, 'bar', 2.1);

```

## User-defined Type
* CREATE TYPE [IF NOT EXISTS] $keyspace.$type_name( field, field, ...)
* DESCRIBE TYPES
* DESCRIBE TYPE $type
* ALTER TYPE $field_name $instruction
* DROP TYPE [IF EXISTS] $type_name



```
cqlsh> CREATE TYPE IF NOT EXISTS cycling.basic_info (
		  birthday timestamp,
		  nationality text,
		  weight text,
		  height text
	 );
cqlsh> ALTER TYPE cycling.basic_info ALTER weight TYPE float;
cqlsh> ALTER TYPE cycling.basic_info ADD release map<timestamp, decimal>;
cqlsh> ALTER TYPE cycling.basic_info RENAME release TO release_at AND weight TO w;
```

## Escaping Characters
Dollar-quoted string constants can be used to create functions, insert data, and select data when complex quoting is needed. Use double dollar signs to enclose the desired string.
```
cqlsh> INSERT INTO cycling.calendar (race_id, race_start_date, race_end_date, race_name) VALUES 
  (201, '2015-02-18', '2015-02-22', $$Women's Tour of New Zealand$$);
  
 race_name text  = 'Women\'s Tour of New Zealand'
```

# Commands
```
cqlsh> /* This is the first line of 
		of a comment that spans multiple
		lines 
	 */
	 desc cluster;			-- End of line comment
cqlsh> desc keyspaces;		// End of line comment
|[
	system_traces  system_schema  system_auth  system  system_distributed
]|
cqlsh> desc keyspace system_auth;
cqlsh> use system_auth;
cql:system_auth> desc tables;
|[
	resource_role_permissons_index  role_permissions  role_members  roles
]|
cql:system_auth> desc table roles;
|[
	CREATE TABLE system_auth.roles (
		role text PRIMARY KEY,
		can_login boolean,
		is_superuser boolean,
		member_of set<text>,
		salted_hash text
	) WITH bloom_filter_fp_chance = 0.01
		AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}
		AND comment = 'role definitions'
		AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}
		AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}
		AND crc_check_chance = 1.0
		AND dclocal_read_repair_chance = 0.0
		AND default_time_to_live = 0
		AND gc_grace_seconds = 7776000
		AND max_index_interval = 2048
		AND memtable_flush_period_in_ms = 3600000
		AND min_index_interval = 128
		AND read_repair_chance = 0.0
		AND speculative_retry = '99PERCENTILE';
]|
```

# Create keyspace and table
http://docs.datastax.com/en/cql/3.3/cql/cql_reference/ref-lexical-valid-chars.html

http://docs.datastax.com/en/cql/3.3/cql/cql_reference/alter_keyspace_r.html

Keyspace and table names must begin with an alpha-numeric character and can only contain alpha-numeric characters and underscores. All other names, such as COLUMN, FUNCTION, AGGREGATE, TYPE, etc., can begin with and contain any character.

To specify a name that contains a special character, like period (.) or hyphen (-), enclose the name in double quotes.

* WITH REPLICATION
	- 'SimpleStrategy' 	'replication_factor' : N  		Assign the same replication factor to the entire cluster. Use for evaluation and single data center test and development environments only.
	- 'NetworkTopologyStrategy'	'datacenter_name' : N   Assign replication factors to each data center in a comma separated list. Use in production environments and multi-DC test and development environments. Data center names must match the snitch DC name; refer to Snitches for more details.
		`REPLICATION = { 
			class' : 'NetworkTopologyStrategy', 
			'datacenter_name' : N [, 'datacenter_name' : N ...] 
		}`
	
* DURABLE_WRITES  enable or disable the commit log for writes
```
cqlsh> CREATE KEYSPACE IF NOT EXISTS test2 WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 } AND durable_writes = true;
cqlsh> use test
cql:test> CREATE TABLE users (
			  userid uuid PRIMARY KEY,
			  first_name text,
			  last_name text,
			  bio blob,
			  emails set<text>,
			  top_scores list<int>,
			  todo map<timestamp, text>,
			  create_time timestamp
			);
			
cql:test> ALTER TABLE users ALTER bio TYPE text;
cql:test> INSERT INTO users 
			(userid, first_name, last_name, emails)
			VALUES
			(cfd66ccc-d857-4e90-b1e5-df98a3d40cd6 , 'Aario', 'Ai', {'AarioAi@gmail.com', 'AarioAi@luexu.com'});
cql:test> UPDATE users SET emails = emails + {'Aario@yiye.cc'} WHERE userid = cfd66ccc-d857-4e90-b1e5-df98a3d40cd6;

cql:test> UPDATE users SET emails = emails - {'Aario@yiye.cc'} WHERE userid = cfd66ccc-d857-4e90-b1e5-df98a3d40cd6;

cql:test> UPDATE users SET emails = {} WHERE userid = cfd66ccc-d857-4e90-b1e5-df98a3d40cd6;

cql:test> SELECT COUNT(*) FROM users;
cql:test> SELECT * FROM users LIMIT 10 ALLOW FILTERING;
cql:test> SELECT * FROM users WHERE TOKEN(userid) >= TOKEN(cfd66ccc-d857-4e90-b1e5-df98a3d40cd6);
cql:test> SELECT TOKEN(userid) FROM users WHERE TOKEN(userid) >= TOKEN(cfd66ccc-d857-4e90-b1e5-df98a3d40cd6);
```

# Batch
http://docs.datastax.com/en/cql/3.1/cql/cql_reference/batch_r.html
Write multiple data modification language (DML: Insert, Update, Delete) statements.
Batches are atomic by default. To achieve atomicity, Cassandra first writes the serialized batch to the batchlog system table that consumes the serialized batch as blob data. When the rows in the batch have been successfully written and persisted (or hinted) the batchlog data is removed. There is a performance penalty for atomicity. If you do not want to incur this penalty, prevent Cassandra from writing to the batchlog system by using the UNLOGGED option: BEGIN UNLOGGED BATCH.

Although an atomic batch guarantees that if any part of the batch succeeds, all of it will, no other transactional enforcement is done at the batch level. For example, there is no batch isolation. Clients are able to read the first updated rows from the batch, while other rows are still being updated on the server. However, transactional row updates within a partition key are isolated: clients cannot read a partial update.

Statement order does not matter within a batch; Cassandra applies all rows using the same timestamp. Use client-supplied timestamps to achieve a particular order.

```
BEGIN [ UNLOGGED | default LOGGED ]  BATCH	    // COUNTER were used in Cassandra 2.0-
  USING TIMESTAMP timestamp
  dml_statement;
  dml_statement;
  ...
APPLY BATCH;

BEGIN BATCH
  INSERT INTO purchases (user, balance) VALUES ('user1', -8) IF NOT EXISTS;
  INSERT INTO purchases (user, expense_id, amount, description, paid)
    VALUES ('user1', 1, 8, 'burrito', false);
APPLY BATCH;
  
BEGIN BATCH
  UPDATE purchases SET balance = -208 WHERE user='user1' IF balance = -8;
  INSERT INTO purchases (user, expense_id, amount, description, paid)
    VALUES ('user1', 2, 200, 'hotel room', false);
APPLY BATCH;

```
BATCH supports setting a client-supplied timestamp, an integer, in the USING clause with one exception: if a DML statement in the batch contains a compare-and-set (CAS) statement, such as the following statement, do not attempt to use a timestamp:

The timestamp applies to all statements in the batch. If not specified, the current time of the insertion (in microseconds) is used. The individual DML statements inside a BATCH can specify a timestamp if one is not specified in the USING clause.

For example, specify a timestamp in an INSERT statement.
```
BEGIN BATCH
  INSERT INTO purchases (user, balance) VALUES ('user1', -8) USING TIMESTAMP 19998889022757000;
  INSERT INTO purchases (user, expense_id, amount, description, paid)
    VALUES ('user1', 1, 8, 'burrito', false);
APPLY BATCH;
```
Verify that balance column has the client-provided timestamp.
```
SELECT balance, WRITETIME(balance) FROM PURCHASES;
|[
balance | writetime_balance
---------+-------------------
      -8 | 19998889022757000
]|
```

In Cassandra 2.1 and later, batches of counters should use UNLOGGED because, unlike other writes in Cassandra, counter updates are not an idempotent operation.
```
BEGIN UNLOGGED BATCH
  UPDATE UserActionCounts SET total = total + 2 WHERE keyalias = 523;
  UPDATE AdminActionCounts SET total = total + 2 WHERE keyalias = 701;
APPLY BATCH;
```
# Order By

http://docs.datastax.com/en/cql/3.3/cql/cql_reference/refClstrOrdr.html
Cassandra 有一个特性就是底层做好分布式了，所以查询排序的时候限制就比较多。
要按照用户才创建时间倒叙查询，必须再创建表的时候就写好。
```
cql:test> CREATE TABLE users (
			  userid uuid PRIMARY KEY,
			  first_name text,
			  last_name text,
			  emails set<text>,
			  top_scores list<int>,
			  todo map<timestamp, text>,
			  create_time timestamp
			  PRIMARY KEY (userid, create_time)
			)
			WITH CLUSTERING ORDER BY (create_time DESC);
```

# Token()
```
cqlsh> SELECT * FROM tb WHERE TOKEN(create_at) > TOKEN('2016-01-01');
cqlsh> SELECT * FROM tb WHERE TOKEN(create_at) < TOKEN('2015-05-26') AND create_at IN ('2015-05-24','2015-05-25');
```
# Writetime()
A table contains a timestamp representing the date/time that a write occurred to a column
Counter column writetime is milliseconds.

* WRITETIME($non_primary_field)
```
cqlsh> SELECT WRITETIME (firstname) FROM cycling.cyclist_points WHERE id=220844bf-4860-49d6-9a4b-6b5d3a79cbfb;
```


# TTL
```
cqlsh> INSERT INTO cycling.calendar (race_id, race_name, race_start_date, race_end_date) VALUES (200, 'placeholder','2015-05-27', '2015-05-27') USING TTL 86400;

cqlsh> SELECT TTL (race_name) from cycling.calendar WHERE race_id = 200;

cqlsh> UPDATE cycling.calendar USING TTL 300 SET race_name = 'dummy' WHERE race_id = 200 AND race_start_date = '2015-05-27' AND race_end_date = '2015-05-27';
```

## Procedure
Cassandra 2.2 or Javascript in Cassandra 3.0, `enable_user_defined_functions` must be set true in `cassandra.yaml` file setting to enable the functions; it is not required for Java in Cassandra 3.0. User-defined functions are defined within a keyspace; if no keyspace is defined, the current keyspace is used. User-defined functions are executed in a sandbox in Cassandra 3.0 and later. 

http://docs.datastax.com/en/cql/3.3/cql/cql_using/useCreateUDA.html

* `CALLED ON NULL INPUT` ensures the function will always be executed.
* `RETURNS NULL ON NULL INPUT` ensures the function will always return NULL if any of the input arguments is NULL.
* `RETURNS` defines the data type of the value returned by the function.
```
cqlsh> CREATE OR REPLACE FUNCTION fLog (input double) CALLED ON NULL INPUT RETURNS double LANGUAGE java AS 'return Double.valueOf(Math.log(input.doubleValue()));';

cqlsh> CREATE OR REPLACE FUNCTION avgState ( state tuple<int,bigint>, val int ) CALLED ON NULL INPUT RETURNS tuple<int,bigint> LANGUAGE java AS 
  'if (val !=null) { state.setInt(0, state.getInt(0)+1); state.setLong(1, state.getLong(1)+val.intValue()); } return state;'; 
  
cqlsh> CREATE AGGREGATE IF NOT EXISTS average ( int ) 
SFUNC avgState STYPE tuple<int,bigint> FINALFUNC avgFinal INITCOND (0,0);

```

